{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import DataFrame as df\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load validation set in tensorflow format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 750 instances from ../robot_or_brain_combined_data/validation.pk.\n",
      "X shape (750, 512) and y shape (750,) with labels:\n",
      "None of the above                  267\n",
      "Acting or Performing machine       168\n",
      "Collaborative or Interactive AI    109\n",
      "Thinking machine                    94\n",
      "Complex AI                          87\n",
      "Mysterious AI                       13\n",
      "Superior human                       8\n",
      "Learning or recognition machine      4\n",
      "Name: y, dtype: int64.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 11>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      9\u001B[0m     train_ds \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataset\u001B[38;5;241m.\u001B[39mfrom_tensor_slices((x, y))\u001B[38;5;241m.\u001B[39mbatch(\u001B[38;5;241m16\u001B[39m)\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m train_ds, class_names, n_features\n\u001B[1;32m---> 11\u001B[0m validation_ds, class_names, n_features \u001B[38;5;241m=\u001B[39m \u001B[43mload_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m../robot_or_brain_combined_data/validation.pk\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [2]\u001B[0m, in \u001B[0;36mload_dataset\u001B[1;34m(path)\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLoaded \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(x)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m instances from \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mX shape \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m and y shape \u001B[39m\u001B[38;5;132;01m{\u001B[39;00my\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m with labels:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mdata[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mvalue_counts()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 9\u001B[0m train_ds \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataset\u001B[38;5;241m.\u001B[39mfrom_tensor_slices((x, y))\u001B[38;5;241m.\u001B[39mbatch(\u001B[38;5;241m16\u001B[39m)\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m train_ds, class_names, n_features\n",
      "\u001B[1;31mNameError\u001B[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "def load_dataset(path):\n",
    "    data = pd.read_pickle(path)\n",
    "    n_features = data['clip_features'][0].shape[-1]\n",
    "    class_names = data['y'].unique()\n",
    "    y = np.array([np.where(class_names == e)[0][0] for e in data['y']])\n",
    "    x = np.concatenate(data['clip_features'].to_numpy())\n",
    "    print(f'Loaded {len(x)} instances from {path}.')\n",
    "    print(f'X shape {x.shape} and y shape {y.shape} with labels:\\n{data[\"y\"].value_counts()}.')\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((x, y)).batch(16)\n",
    "    return train_ds, class_names, n_features\n",
    "validation_ds, class_names, n_features = load_dataset('../robot_or_brain_combined_data/validation.pk')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class_list = class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trues = [class_list[int(y)] for _x, y in validation_ds.unbatch()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Print class counts for each split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df([y for y in trues]).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Some of these counts are horrible. The number of examples in 'Learning or recognition machine', 'Superior human' and 'Mysterious AI' are really too small. Also, the 'None of the above' class is very large, although that's not really a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load our trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# model = tf.keras.models.load_model('./fine_tuned_model_3m6herki')\n",
    "# model = tf.keras.models.load_model('./fine_tuned_model_3f0vzk68')\n",
    "# model = tf.keras.models.load_model('./fine_tuned_model_qdesgan9')\n",
    "model = tf.keras.models.load_model('./clip_features_model_kuw3ehqp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "logits = model.predict(validation_ds)\n",
    "predicted = [class_list[v] for v in np.argmax(logits, 1)]\n",
    "from pandas import DataFrame as df\n",
    "print(df(predicted).value_counts())\n",
    "print(df(trues).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Performance metrics for ResNet50 based classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "confusion = confusion_matrix(trues, predicted)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion,                               display_labels=class_list)\n",
    "_ = disp.plot(cmap='Greys', xticks_rotation='vertical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from utils import print_performance_metrics\n",
    "\n",
    "print_performance_metrics(trues, predicted, list(class_list))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robot",
   "language": "python",
   "name": "robot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}