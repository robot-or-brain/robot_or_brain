{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import DataFrame as df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load the 3 dataset splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from utils import load_dataset\n",
    "\n",
    "val_set, _ = load_dataset('validation')\n",
    "test_set, _ = load_dataset('test')\n",
    "train_set, class_list = load_dataset('train')\n",
    "datasets = {'validation':val_set, 'test':test_set,'train':train_set}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Print class counts for each split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>validation</th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>None of the above</th>\n",
       "      <td>267</td>\n",
       "      <td>445</td>\n",
       "      <td>1067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acting or Performing machine</th>\n",
       "      <td>168</td>\n",
       "      <td>281</td>\n",
       "      <td>674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Collaborative or Interactive AI</th>\n",
       "      <td>109</td>\n",
       "      <td>182</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thinking machine</th>\n",
       "      <td>94</td>\n",
       "      <td>156</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Complex AI</th>\n",
       "      <td>87</td>\n",
       "      <td>145</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mysterious AI</th>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Superior human</th>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Learning or recognition machine</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 validation  test  train\n",
       "None of the above                       267   445   1067\n",
       "Acting or Performing machine            168   281    674\n",
       "Collaborative or Interactive AI         109   182    438\n",
       "Thinking machine                         94   156    373\n",
       "Complex AI                               87   145    347\n",
       "Mysterious AI                            13    21     50\n",
       "Superior human                            8    14     34\n",
       "Learning or recognition machine           4     6     16"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df({k:v['y'].value_counts() for k,v  in datasets.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Some of these counts are horrible. The number of examples in 'Learning or recognition machine', 'Superior human' and 'Mysterious AI' are really too small. Also, the 'None of the above' class is very large, although that's not really a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create a prompt for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Machine,robot or product, performing an act or task': 'Acting or Performing machine',\n",
       " 'AI interacting with humans, AI performs a task that supports humans.': 'Collaborative or Interactive AI',\n",
       " 'AI visualized as complex data, complex interactions/nodes/networks': 'Complex AI',\n",
       " 'AI scanning or recognizing data points in traffic, shops, or faces': 'Learning or recognition machine',\n",
       " 'AI working “magically” or in a mysterious way.': 'Mysterious AI',\n",
       " 'car horse cat house bicycle cook shoe plane spider animal weapon boat tree': 'None of the above',\n",
       " 'AI depicted as technology that is created and/or controlled by humans.': 'Superior human',\n",
       " 'AI visualized as a brain, face, eye, android storing large amounts of data': 'Thinking machine'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acting = \"Machine,robot or product, performing an act or task\"\n",
    "collab = \"AI interacting with humans, AI performs a task that supports humans.\"\n",
    "complx = \"AI visualized as complex data, complex interactions/nodes/networks\"\n",
    "learning = \"AI scanning or recognizing data points in traffic, shops, or faces\"\n",
    "mysterious = \"AI working “magically” or in a mysterious way.\"\n",
    "other = \"car horse cat house bicycle cook shoe plane spider animal weapon boat tree\"\n",
    "superior = \"AI depicted as technology that is created and/or controlled by humans.\"\n",
    "thinking = \"AI visualized as a brain, face, eye, android storing large amounts of data\"\n",
    "\n",
    "prompts = [acting, collab, complx, learning, mysterious, other, superior, thinking]\n",
    "classes_by_prompt = {k:v for k, v in zip(prompts, class_list)}\n",
    "classes_by_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create classifier using clip and the prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import clip\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def predict_image_with_clip(image_path):\n",
    "    #See first example at https://github.com/openai/CLIP#usage\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "    img = Image.open(image_path)\n",
    "    image = preprocess(img).unsqueeze(0).to(device)\n",
    "    text = clip.tokenize(prompts).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits_per_image, logits_per_text = model(image, text)\n",
    "        probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "\n",
    "    prediction = np.argmax(probs)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "    # for prob, label in sorted(zip(probs[0], labels), key=lambda x : x[0], reverse=True):\n",
    "    #     print(f'{prob:.2f} {label}')\n",
    "\n",
    "predict_image_with_clip(val_set['paths'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▌                                                                          | 25/750 [04:30<2:10:46, 10.82s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "predicted = [class_list[predict_image_with_clip(p)] for p in tqdm(val_set['paths'][::])]\n",
    "trues = val_set['y'][::].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame as df\n",
    "print(df(predicted).value_counts())\n",
    "print(df(trues).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Performance metrics for clip based classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "confusion = confusion_matrix(trues, predicted)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion,                               display_labels=class_list)\n",
    "_ = disp.plot(cmap='Greys', xticks_rotation='vertical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from utils import print_performance_metrics\n",
    "\n",
    "print_performance_metrics(trues, predicted, class_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}